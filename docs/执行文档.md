# 生图工具（Image Generation Tool）执行文档

## 目标

把“文生图”能力接入当前项目的 **Agent Tool（OpenAI function tool）** 体系，让智能体能在对话中调用工具生成图片，并把图片作为 **Acontext Artifact** 存储/回显。

本文档只描述**接入思路与落地步骤**（不直接实现代码）。

---

## 当前项目的 Tool 实现方式（你现有的基线）

你现在的工具链路是标准的 “OpenAI tools + 服务器执行器 + SSE 回传”：

- **工具列表展示**：`GET /api/tools`
  - 文件：`app/api/tools/route.ts`
  - 作用：把后端注册的 OpenAI tool schema 转成 UI 可展示的 `{name, description, parameters[]}`。
- **工具注入模型**：`POST /api/chatbot`
  - 文件：`app/api/chatbot/route.ts`
  - 作用：根据 `CHATBOT_ENABLE_TOOLS` 和前端 `enabledToolNames` 过滤工具，并把 `tools` 传入 `chatCompletionStream/chatCompletion`。
- **工具执行入口**：`lib/openai-client.ts`
  - 作用：在 `executeToolCall()` 里按 tool name 分发执行（browser_use / experience_search / todo / acontext disk tools）。
- **前端展示工具与调用过程**：`components/chatbot-panel.tsx`
  - 作用：加载 `/api/tools` 展示开关；聊天走 SSE 时展示 tool_call_start/step/complete。

> 结论：新增“生图工具”的标准做法是：**新增一个 tool schema + 一个 runXXX 执行函数 + 在 openai-client 分发 + 在 chatbot route 注入 + 在 /api/tools 暴露给 UI**。

---

## 生图工具的定位（建议）

### 为什么建议“工具返回 artifact 句柄”，而不是直接返回 base64

第三方模型返回的 `inlineData.data` 是 base64，图片可能很大。直接把 base64 塞进：

- SSE 事件（会很大、易断流）
- Chat message（会污染上下文、成本高）
- 数据库存储（很快膨胀）

更稳的方式是：

- 工具侧拿到 base64 → 服务端解码成二进制 → **上传到 Acontext Disk 作为 artifact**
- 工具返回：
  - `artifactPath`（推荐）+ `mimeType` + 可选 `publicUrl`
  - 前端展示时用你现有的 `/api/acontext/artifacts/content` 去取内容/直链

---

## 第三方生图接口（参考你给的 Python）

### 请求

- URL：`{base_url}/v1beta/models/{model}:generateContent`（其中 `{model}` **来自服务端环境变量**，不接受 tool 入参覆盖）
- Header：
  - `Content-Type: application/json`
  - `x-goog-api-key: <API_KEY>`
- Body（核心字段）：
  - `contents[0].parts[0].text = prompt`
  - `generationConfig.responseModalities = ["TEXT", "IMAGE"]`
  - `generationConfig.imageConfig.aspectRatio = ratio`
  - `generationConfig.imageConfig.imageSize = size`

### 响应解析

从 `candidates[0].content.parts[]` 中遍历：

- 如果 part 包含 `inlineData`：
  - `inlineData.data`：base64（图片 bytes）
  - `inlineData.mimeType`：如 `image/png`
- 如果 part 只是文本：可以作为模型解释信息一起返回（可选）

---

## Tool 设计（建议的 Schema）

### Tool 名称

建议：`image_generate`（清晰、单一职责）

### 入参（args）

- `prompt`（string, required）：提示词
- `size`（string, optional）：默认 `1K`（枚举：`1K | 2K | 4K`）
- `ratio`（string, optional）：默认 `1:1`（枚举：`1:1 | 16:9 | 9:16 | 3:4 | 4:3 | 2:3 | 3:2 | 4:5 | 5:4 | 21:9`）
- `output_dir`（string, optional）：如果你希望落到 disk 的某个目录，例如 `"/generated_images"`（最终是否需要取决于你的 Acontext Disk 写入 API）

> 注意：工具参数尽量“可控、可校验、可枚举”，避免让模型传入任意复杂对象。
>
> 补充约束：**不允许模型在 tool call 里选择生图模型**。实际使用的模型由服务端从 `.env`（例如 `IMAGE_GEN_DEFAULT_MODEL`）读取。

---

## Tool 执行结果（建议的返回结构）

建议返回一个 JSON 对象（会被 stringify 进 tool role message）：

- `images`: Array\<{
  - `mimeType`: string（如 `image/png`）
  - `artifactPath`: string（推荐，Acontext disk 内路径或 artifact 唯一标识）
  - `publicUrl?`: string（可选，如果 Acontext 返回了可访问直链）
  - `sizeBytes?`: number（可选，方便 UI 展示）
}\>
- `text?`: string（可选，模型返回的文本部分）
- `provider`: string（例如 `openai-next` 或 `gemini-via-openai-next`）
- `model`: string（服务端实际使用的模型，用于回显/排障；不是由 tool 入参传入）

前端展示策略：

- 优先用 `publicUrl` 直接 `<img src=...>`
- 没有 `publicUrl` 时：调用你现有的 `/api/acontext/artifacts/content?file_path=...&disk_id=...` 取 base64/mime，然后渲染 data URL

---

## 落地步骤（需要改哪些文件）

下面是“照你现有工具模式接入”的最小改动清单。

### 1) 新增工具文件：schema + runner

新增：`lib/acontext-image-generate-tool.ts`（命名可调整）

包含：

- `getImageGenerateToolSchema`：OpenAI tool schema（`type:"function"` + `function:{name,description,parameters}`）
- `runImageGenerate(args, context)`：
  - 读取服务端环境变量（API key/baseUrl）
  - 调用第三方 `generateContent`
  - 解析 `inlineData.data` base64
  - **上传到 Acontext Disk 生成 artifact**（推荐）
  - 返回上面约定的结果结构

需要的环境变量（建议）：

- `IMAGE_GEN_API_KEY`：第三方 key（对应 Python 的 `x-goog-api-key`）
- `IMAGE_GEN_BASE_URL`：默认 `https://api.openai-next.com`
- `IMAGE_GEN_DEFAULT_MODEL`：默认 `gemini-3-pro-image-preview`

> 安全要求：key 只允许在服务端读取，绝不下发到浏览器。

### 2) 在 `GET /api/tools` 暴露该工具给前端

文件：`app/api/tools/route.ts`

把 `getImageGenerateToolSchema` 加入 `schemas` 数组，这样 UI 能看到工具并允许勾选。

### 3) 在 `POST /api/chatbot` 中把工具注入给模型

文件：`app/api/chatbot/route.ts`

把 `getImageGenerateToolSchema` 加入：

- `availableTools` 数组（与 experience_search/todo/browser_use 同级）

这样模型才“看得见”这个工具并会主动 function call。

### 4) 在工具执行器里分发执行

文件：`lib/openai-client.ts`

在 `executeToolCall()` 中新增分支：

- `if (name === "image_generate") { ... }`

并调用 `runImageGenerate()`。

（同时也可以提供 `isImageGenerateToolName()` 的守卫函数，和现有 disk/todo/experience_search 的风格一致。）

### 5) Acontext Disk 写入/产物管理（推荐）

你现在已经有 disk 工具和上传逻辑（例如 `uploadFileToAcontext` 用于附件）。生图工具建议复用同类逻辑：

- 把图片 bytes 上传到 session 对应的 `acontextDiskId`（如果存在）
- 文件命名建议包含 timestamp + 随机串，例如 `generated/2026-01-14/image_...png`

这样你现有的：

- `/api/acontext/artifacts/content`
- 以及 disk tools（list/read/download）

都能直接复用，用户也能管理生成物。

---

## 与 UI 的衔接（你现在的前端不需要“特殊适配”也能跑）

因为你们 UI 已经会展示 tool call 的结果（JSON stringify），所以最小实现下：

- 工具执行完会把结果 JSON 显示出来（包含 `publicUrl` 或 `artifactPath`）

想要更好的体验（可选增强）：

- 如果 tool result 里包含 `publicUrl`：在 `chatbot-panel.tsx` 对 tool result 做识别并渲染 `<img>`
- 如果只有 `artifactPath`：自动调用 `/api/acontext/artifacts/content` 获取内容并渲染

---

## 错误处理与可观测性（必须）

建议规范化错误：

- 输入校验错误：`400`（prompt 为空、size/ratio 不合法）
- 上游失败：把 `status_code + response.text` 截断后返回（避免塞太长）
- 上传失败：返回可诊断信息（diskId、目标路径、错误消息）

日志建议：

- tool start：记录 `model/size/ratio/prompt_length`
- tool end：记录 `image_count/total_bytes`
- 禁止打印敏感 key

---

## 建议的最小验收标准（Definition of Done）

- 在 UI 里能看到 `image_generate` 出现在工具列表（`/api/tools`）
- 勾选该工具后，模型可以发起 `image_generate` tool call
- 服务端能成功调用上游并解析到至少一张 `inlineData` 图片
- 图片能被保存为 Acontext artifact，返回 `artifactPath`（或 `publicUrl`）
- 前端至少能拿到可用链接（先不做美化也 ok）

---

## 你需要先确认的 3 个点（决定最终接口细节）

1) **生成的图片要存哪里？**
   - 推荐：存 Acontext Disk（跟会话绑定）
2) **你希望工具返回 `publicUrl` 直链，还是统一返回 `artifactPath`？**
   - 推荐：两者都返回（如果上游能给 publicUrl，就给；否则用 artifactPath 回源）
3) **上游 provider 是否固定为你给的 `api.openai-next.com`？**
   - 如果未来可能切换（OpenAI/Replicate/自建），建议抽象成 provider 配置


